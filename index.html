<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RhythmGuassian - Remote Physiological Measurement</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.8/dist/chart.umd.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        primary: '#3B82F6', // 蓝色主调，体现科研严谨性
                        secondary: '#10B981', // 绿色辅助，关联生理信号
                        dark: '#1E293B',
                        light: '#F8FAFC'
                    },
                    fontFamily: {
                        inter: ['Inter', 'sans-serif'],
                    },
                }
            }
        }
    </script>
    
    <style type="text/tailwindcss">
        @layer utilities {
            .content-auto {
                content-visibility: auto;
            }
            .section-fade {
                opacity: 0;
                transform: translateY(20px);
                transition: opacity 0.6s ease, transform 0.6s ease;
            }
            .section-visible {
                opacity: 1;
                transform: translateY(0);
            }
            .text-balance {
                text-wrap: balance;
            }
        }
    </style>
</head>

<body class="font-inter bg-white text-dark">
    <!-- 导航栏 -->
    <header class="fixed w-full bg-white/95 backdrop-blur-sm shadow-sm z-50 transition-all duration-300">
        <div class="container mx-auto px-4 py-3 flex justify-between items-center">
            <a href="#" class="flex items-center gap-2">
                <div class="w-10 h-10 rounded-lg bg-primary/10 flex items-center justify-center">
                    <i class="fa fa-heartbeat text-primary text-xl"></i>
                </div>
                <span class="text-xl font-bold">RhythmGuassian</span>
            </a>
            
            <!-- 桌面导航 -->
            <nav class="hidden md:flex items-center gap-8">
                <a href="#overview" class="hover:text-primary transition-colors">Overview</a>
                <a href="#method" class="hover:text-primary transition-colors">Method</a>
                <a href="#results" class="hover:text-primary transition-colors">Results</a>
                <a href="#team" class="hover:text-primary transition-colors">Team</a>
                <a href="https://github.com/LuPaoPao/RhythmGuassian" target="_blank" class="px-5 py-2 bg-primary text-white rounded-lg hover:bg-primary/90 transition-colors flex items-center gap-2">
                    <i class="fa fa-github"></i> Code
                </a>
            </nav>
            
            <!-- 移动端菜单按钮 -->
            <button id="menuToggle" class="md:hidden text-xl">
                <i class="fa fa-bars"></i>
            </button>
        </div>
        
        <!-- 移动端菜单 -->
        <div id="mobileMenu" class="hidden md:hidden bg-white border-t">
            <div class="container mx-auto px-4 py-4 flex flex-col gap-4">
                <a href="#overview" class="py-2 hover:text-primary transition-colors">Overview</a>
                <a href="#method" class="py-2 hover:text-primary transition-colors">Method</a>
                <a href="#results" class="py-2 hover:text-primary transition-colors">Results</a>
                <a href="#team" class="py-2 hover:text-primary transition-colors">Team</a>
                <a href="https://github.com/LuPaoPao/RhythmGuassian" target="_blank" class="py-2 bg-primary text-white rounded-lg text-center hover:bg-primary/90 transition-colors">
                    <i class="fa fa-github mr-2"></i> Code
                </a>
            </div>
        </div>
    </header>

    <main>
        <!-- 英雄区域 -->
        <section class="pt-32 pb-20 md:pt-40 md:pb-28 bg-gradient-to-b from-light to-white">
            <div class="container mx-auto px-4">
                <div class="flex flex-col md:flex-row items-center gap-12">
                    <div class="md:w-1/2 space-y-6">
                        <div class="inline-block px-4 py-1.5 bg-primary/10 text-primary rounded-full text-sm font-medium">
                            <i class="fa fa-flask mr-2"></i> Research Project
                        </div>
                        <h1 class="text-[clamp(2rem,5vw,3.5rem)] font-bold leading-tight">
                            RhythmGuassian: Repurposing Generalizable Gaussian Model For Remote Physiological Measurement
                        </h1>
                        <p class="text-lg text-gray-600 max-w-lg">
                            A novel framework for robust remote Photoplethysmography (rPPG) signal extraction using 4D Gaussian representations to address motion entanglement issues.
                        </p>
                        <div class="flex flex-wrap gap-4 pt-4">
                            <a href="https://github.com/LuPaoPao/RhythmGuassian" target="_blank" class="px-6 py-3 bg-primary text-white rounded-lg hover:bg-primary/90 transition-all shadow-lg shadow-primary/20">
                                <i class="fa fa-github mr-2"></i> GitHub Repository
                            </a>
                            <a href="#method" class="px-6 py-3 bg-white text-dark border border-gray-300 rounded-lg hover:bg-gray-50 transition-all">
                                <i class="fa fa-book mr-2"></i> Learn More
                            </a>
                        </div>
                    </div>
                    <div class="md:w-1/2 relative">
                        <div class="rounded-xl overflow-hidden shadow-2xl">
                            <!-- 这里可以替换为实际框架图 -->
                            <img src="https://picsum.photos/id/1083/800/600" alt="RhythmGuassian Framework Overview" class="w-full h-auto">
                            <div class="absolute inset-0 bg-gradient-to-t from-black/60 to-transparent flex items-end">
                                <div class="p-6 text-white">
                                    <p class="font-medium">Framework Overview</p>
                                    <p class="text-sm text-gray-200">4D Gaussian-based rPPG signal extraction pipeline</p>
                                </div>
                            </div>
                        </div>
                        <!-- 装饰元素 -->
                        <div class="absolute -bottom-6 -left-6 w-24 h-24 bg-secondary/20 rounded-full blur-xl"></div>
                        <div class="absolute -top-6 -right-6 w-32 h-32 bg-primary/20 rounded-full blur-xl"></div>
                    </div>
                </div>
            </div>
        </section>

        <!-- 项目概述 -->
        <section id="overview" class="py-20 section-fade">
            <div class="container mx-auto px-4">
                <div class="max-w-3xl mx-auto text-center mb-16">
                    <h2 class="text-3xl md:text-4xl font-bold mb-6">Abstract</h2>
                    <div class="bg-light p-8 rounded-xl text-left shadow-sm border border-gray-100">
                        <p class="text-gray-700 leading-relaxed">
                            Remote Photoplethysmography (rPPG) enables non-contact extraction of physiological signals, providing significant advantages in medical monitoring, emotion recognition, and face anti-spoofing. However, the extraction of reliable rPPG signals is hindered by motion variations in real-world environments, leading to entanglement issues.
                        </p>
                        <p class="text-gray-700 leading-relaxed mt-4">
                            To address this challenge, we employ the Generalizable Gaussian Model (GGM) to disentangle geometry and chroma components with 4D Gaussian representations. We propose a "4D virtual camera" to construct extra Gaussian parameters describing view and motion changes, enabling video rendering with fixed virtual camera parameters. 
                        </p>
                        <p class="text-gray-700 leading-relaxed mt-4">
                            Further, we design Explicit Motion Modeling (EMM) to decouple motion variation in an unsupervised manner, and Explicit Chroma Modeling (ECM) to decouple specular, physiological, and noise signals. We validate our approach by expanding existing rPPG datasets to include various motion and illumination interference scenarios, demonstrating effectiveness in real-world settings.
                        </p>
                    </div>
                </div>
                
                <div class="grid md:grid-cols-3 gap-8">
                    <div class="bg-white p-8 rounded-xl shadow-lg hover:shadow-xl transition-shadow border border-gray-100">
                        <div class="w-14 h-14 bg-primary/10 rounded-lg flex items-center justify-center mb-6">
                            <i class="fa fa-signal text-primary text-2xl"></i>
                        </div>
                        <h3 class="text-xl font-bold mb-3">rPPG Extraction</h3>
                        <p class="text-gray-600">
                            Non-contact physiological signal extraction with improved robustness against motion artifacts and environmental interference.
                        </p>
                    </div>
                    
                    <div class="bg-white p-8 rounded-xl shadow-lg hover:shadow-xl transition-shadow border border-gray-100">
                        <div class="w-14 h-14 bg-secondary/10 rounded-lg flex items-center justify-center mb-6">
                            <i class="fa fa-cubes text-secondary text-2xl"></i>
                        </div>
                        <h3 class="text-xl font-bold mb-3">4D Gaussian Model</h3>
                        <p class="text-gray-600">
                            Generalizable Gaussian representation that disentangles geometry and chroma components for more reliable signal extraction.
                        </p>
                    </div>
                    
                    <div class="bg-white p-8 rounded-xl shadow-lg hover:shadow-xl transition-shadow border border-gray-100">
                        <div class="w-14 h-14 bg-primary/10 rounded-lg flex items-center justify-center mb-6">
                            <i class="fa fa-shield text-primary text-2xl"></i>
                        </div>
                        <h3 class="text-xl font-bold mb-3">Real-World Robustness</h3>
                        <p class="text-gray-600">
                            Explicit modeling techniques that handle motion variations and illumination changes in practical environments.
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- 方法介绍 -->
        <section id="method" class="py-20 bg-light section-fade">
            <div class="container mx-auto px-4">
                <div class="max-w-3xl mx-auto text-center mb-16">
                    <h2 class="text-3xl md:text-4xl font-bold mb-6">Proposed Method</h2>
                    <p class="text-lg text-gray-600">
                        Our framework leverages 4D Gaussian representations and explicit modeling techniques to address the core challenges in rPPG extraction.
                    </p>
                </div>
                
                <!-- 框架图 -->
                <div class="mb-16 bg-white p-4 md:p-8 rounded-xl shadow-lg">
                    <div class="flex justify-center">
                        <!-- 替换为实际框架图 -->
                        <img src="https://picsum.photos/id/1074/1200/600" alt="RhythmGuassian Framework" class="w-full max-w-4xl rounded-lg">
                    </div>
                    <p class="text-center text-gray-500 mt-4 text-sm">
                        Figure 1: Overview of the RhythmGuassian framework, including Generalized Gaussian Model, Explicit Motion Modeling, 4D Virtual Camera, and Explicit Chroma Modeling.
                    </p>
                </div>
                
                <!-- 核心组件 -->
                <div class="grid md:grid-cols-2 gap-12">
                    <div class="bg-white p-8 rounded-xl shadow-lg">
                        <h3 class="text-2xl font-bold mb-4 flex items-center gap-2">
                            <span class="w-8 h-8 rounded-full bg-primary text-white flex items-center justify-center text-sm">1</span>
                            4D Virtual Camera
                        </h3>
                        <p class="text-gray-600 mb-4">
                            Constructs extra Gaussian parameters to describe view and motion changes, enabling video rendering with fixed virtual camera parameters even when no real camera parameters are available in the dataset.
                        </p>
                        <p class="text-gray-600">
                            This innovation allows us to render video from 4D Gaussian representations, facilitating effective training and evaluation.
                        </p>
                    </div>
                    
                    <div class="bg-white p-8 rounded-xl shadow-lg">
                        <h3 class="text-2xl font-bold mb-4 flex items-center gap-2">
                            <span class="w-8 h-8 rounded-full bg-primary text-white flex items-center justify-center text-sm">2</span>
                            Explicit Motion Modeling (EMM)
                        </h3>
                        <p class="text-gray-600 mb-4">
                            Achieves spatial motion compensation in 4D Gaussian space by applying horizontal displacement ($\Delta h$), width variation ($\Delta w$), and scale adjustment ($\Delta s$) parameters to the Gaussian splatting set.
                        </p>
                        <p class="text-gray-600">
                            This unsupervised approach effectively decouples motion variations from physiological signals.
                        </p>
                    </div>
                    
                    <div class="bg-white p-8 rounded-xl shadow-lg">
                        <h3 class="text-2xl font-bold mb-4 flex items-center gap-2">
                            <span class="w-8 h-8 rounded-full bg-primary text-white flex items-center justify-center text-sm">3</span>
                            Explicit Chroma Modeling (ECM)
                        </h3>
                        <p class="text-gray-600 mb-4">
                            Tailored to decouple specular ($V_s$), physiological ($V_d$), and noise ($V_n$) signals through specialized loss functions.
                        </p>
                        <p class="text-gray-600">
                            Spatiotemporal Consistency Loss enforces inter-frame stability of physiological components, while Motion-Aware Chroma Consistency Loss synchronizes pose parameters with noise-associated components.
                        </p>
                    </div>
                    
                    <div class="bg-white p-8 rounded-xl shadow-lg">
                        <h3 class="text-2xl font-bold mb-4 flex items-center gap-2">
                            <span class="w-8 h-8 rounded-full bg-primary text-white flex items-center justify-center text-sm">4</span>
                            Generalizable Gaussian Model (GGM)
                        </h3>
                        <p class="text-gray-600 mb-4">
                            Processes spatiotemporal maps (STMap) from input videos through an encoder, feeding into both a physiological decoder for signal prediction and a Gaussian Adaptor to obtain 4D Gaussian Maps.
                        </p>
                        <p class="text-gray-600">
                            This dual-path architecture enables effective disentanglement of geometry and chroma components.
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- 实验结果 -->
        <section id="results" class="py-20 section-fade">
            <div class="container mx-auto px-4">
                <div class="max-w-3xl mx-auto text-center mb-16">
                    <h2 class="text-3xl md:text-4xl font-bold mb-6">Experimental Results</h2>
                    <p class="text-lg text-gray-600">
                        Our method demonstrates superior performance in extracting reliable rPPG signals under various motion and illumination interference scenarios.
                    </p>
                </div>
                
                <div class="grid md:grid-cols-2 gap-12 items-center">
                    <div>
                        <div class="bg-white p-8 rounded-xl shadow-lg mb-8">
                            <h3 class="text-xl font-bold mb-6">Performance Comparison</h3>
                            <canvas id="resultsChart" width="400" height="300"></canvas>
                        </div>
                        <div class="bg-light p-6 rounded-xl">
                            <h4 class="font-bold mb-3">
